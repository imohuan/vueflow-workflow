import {
  BaseFlowNode,
  type PortConfig,
  type NodeStyleConfig,
  type NodeExecutionContext,
  type NodeExecutionResult,
} from "../BaseFlowNode";
import OpenAI from "openai";
import type { ChatCompletionMessageParam } from "openai/resources/chat/completions";

/**
 * æ¶ˆæ¯ç±»å‹
 */
export interface Message {
  role: "system" | "user" | "assistant";
  type: "text" | "image";
  message: string;
}

/**
 * OpenAI LLM èŠ‚ç‚¹
 * ç”¨äºè°ƒç”¨ OpenAI å…¼å®¹çš„å¤§æ¨¡å‹ API
 */
export class OpenAILlmNode extends BaseFlowNode {
  readonly type = "openaiLlm";
  readonly label = "AI å¤§æ¨¡å‹";
  readonly description = "è°ƒç”¨ OpenAI å…¼å®¹çš„å¤§æ¨¡å‹ API";
  readonly category = "AI";

  protected defineInputs(): PortConfig[] {
    return [
      {
        name: "baseUrl",
        type: "string",
        description: "API åŸºç¡€ URL",
        required: true,
        defaultValue: "https://api.openai.com/v1",
      },
      {
        name: "apiKey",
        type: "string",
        description: "API Key",
        required: true,
      },
      {
        name: "model",
        type: "string",
        description: "æ¨¡å‹åç§°",
        required: true,
        defaultValue: "gpt-3.5-turbo",
      },
      {
        name: "systemMessages",
        type: "array",
        description: "ç³»ç»Ÿæç¤ºè¯åˆ—è¡¨",
        defaultValue: [],
      },
      {
        name: "userMessages",
        type: "array",
        description: "ç”¨æˆ·æç¤ºè¯åˆ—è¡¨",
        defaultValue: [],
      },
      {
        name: "temperature",
        type: "number",
        description: "æ¸©åº¦å‚æ•°ï¼ˆ0-2ï¼‰",
        defaultValue: 1,
      },
      {
        name: "maxTokens",
        type: "number",
        description: "æœ€å¤§ token æ•°",
        defaultValue: 2048,
      },
      {
        name: "topP",
        type: "number",
        description: "Top P å‚æ•°ï¼ˆ0-1ï¼‰",
        defaultValue: 1,
      },
      {
        name: "frequencyPenalty",
        type: "number",
        description: "é¢‘ç‡æƒ©ç½šï¼ˆ-2 åˆ° 2ï¼‰",
        defaultValue: 0,
      },
      {
        name: "presencePenalty",
        type: "number",
        description: "å­˜åœ¨æƒ©ç½šï¼ˆ-2 åˆ° 2ï¼‰",
        defaultValue: 0,
      },
    ];
  }

  protected defineOutputs(): PortConfig[] {
    return [
      {
        name: "response",
        type: "string",
        description: "AI å“åº”å†…å®¹",
      },
      {
        name: "fullResponse",
        type: "object",
        description: "å®Œæ•´çš„ API å“åº”",
      },
    ];
  }

  protected getStyleConfig(): NodeStyleConfig {
    return {
      headerColor: ["#10b981", "#059669"], // ç»¿è‰²æ¸å˜
      icon: "ğŸ¤–",
      showIcon: true,
    };
  }

  async execute(
    inputs: Record<string, any>,
    context: NodeExecutionContext
  ): Promise<NodeExecutionResult> {
    try {
      // è·å–è¾“å…¥å‚æ•°
      let baseUrl = this.getInput<string>(
        inputs,
        "baseUrl",
        "https://api.openai.com/v1"
      );
      const apiKey = this.getInput<string>(inputs, "apiKey", "");
      const model = this.getInput<string>(inputs, "model", "gpt-3.5-turbo");
      const systemMessages = this.getInput<Message[]>(
        inputs,
        "systemMessages",
        []
      );
      const userMessages = this.getInput<Message[]>(inputs, "userMessages", []);
      const temperature = this.getInput<number>(inputs, "temperature", 1);
      const maxTokens = this.getInput<number>(inputs, "maxTokens", 2048);
      const topP = this.getInput<number>(inputs, "topP", 1);
      const frequencyPenalty = this.getInput<number>(
        inputs,
        "frequencyPenalty",
        0
      );
      const presencePenalty = this.getInput<number>(
        inputs,
        "presencePenalty",
        0
      );

      // éªŒè¯å¿…å¡«å‚æ•°
      const validation = this.validateInputs(inputs);
      if (!validation.valid) {
        return this.createError(validation.errors.join("; "));
      }

      // æ£€æŸ¥æ˜¯å¦ä¸­æ­¢
      if (context.signal?.aborted) {
        return this.createError("è¯·æ±‚å·²ä¸­æ­¢");
      }

      // å¤„ç† baseUrlï¼šç§»é™¤æœ«å°¾æ–œæ ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰ /v1 åç¼€ï¼Œå¦‚æœæ²¡æœ‰åˆ™è‡ªåŠ¨è¡¥å…¨
      baseUrl = baseUrl.replace(/\/$/, ""); // ç§»é™¤æœ«å°¾çš„æ–œæ 
      if (!baseUrl.endsWith("/v1")) {
        baseUrl = `${baseUrl}/v1`;
      }

      // åˆ›å»º OpenAI å®¢æˆ·ç«¯
      const client = new OpenAI({
        apiKey,
        baseURL: baseUrl,
      });

      // æ„å»ºæ¶ˆæ¯åˆ—è¡¨
      const messages: ChatCompletionMessageParam[] = [];

      // æ·»åŠ ç³»ç»Ÿæ¶ˆæ¯
      if (Array.isArray(systemMessages) && systemMessages.length > 0) {
        for (const msg of systemMessages) {
          if (msg.role === "system" && msg.message) {
            if (msg.type === "text") {
              messages.push({
                role: "system",
                content: msg.message,
              } as ChatCompletionMessageParam);
            } else if (msg.type === "image") {
              // å›¾ç‰‡ç±»å‹æ¶ˆæ¯ - system è§’è‰²ä¸æ”¯æŒå›¾ç‰‡å†…å®¹
              // OpenAI API çš„ system è§’è‰²åªæ”¯æŒæ–‡æœ¬å†…å®¹
              // å°†å›¾ç‰‡ç±»å‹çš„ç³»ç»Ÿæ¶ˆæ¯è½¬æ¢ä¸ºç”¨æˆ·æ¶ˆæ¯ï¼Œé¿å…ä¸¢å¤±ä¿¡æ¯
              messages.push({
                role: "user",
                content: [
                  {
                    type: "image_url",
                    image_url: { url: msg.message },
                  },
                ],
              } as ChatCompletionMessageParam);
            }
          }
        }
      }

      // æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
      if (Array.isArray(userMessages) && userMessages.length > 0) {
        for (const msg of userMessages) {
          if (msg.role === "user" && msg.message) {
            if (msg.type === "text") {
              messages.push({
                role: "user",
                content: msg.message,
              } as ChatCompletionMessageParam);
            } else if (msg.type === "image") {
              // å›¾ç‰‡ç±»å‹æ¶ˆæ¯
              messages.push({
                role: "user",
                content: [
                  {
                    type: "image_url",
                    image_url: { url: msg.message },
                  },
                ],
              } as ChatCompletionMessageParam);
            }
          }
        }
      }

      // å¦‚æœæ²¡æœ‰æ¶ˆæ¯ï¼Œè¿”å›é”™è¯¯
      if (messages.length === 0) {
        return this.createError("è‡³å°‘éœ€è¦æä¾›ä¸€ä¸ªç³»ç»Ÿæˆ–ç”¨æˆ·æ¶ˆæ¯");
      }

      // ä½¿ç”¨ OpenAI åº“åˆ›å»ºèŠå¤©å®Œæˆ
      const completion = await client.chat.completions.create(
        {
          model,
          messages,
          temperature: Math.max(0, Math.min(2, temperature)),
          max_tokens: Math.max(1, maxTokens),
          top_p: Math.max(0, Math.min(1, topP)),
          frequency_penalty: Math.max(-2, Math.min(2, frequencyPenalty)),
          presence_penalty: Math.max(-2, Math.min(2, presencePenalty)),
        },
        {
          signal: context.signal, // æ”¯æŒ AbortSignal
        }
      );

      // æå–å“åº”å†…å®¹
      const responseText = completion.choices?.[0]?.message?.content || "";

      // æ„å»ºå®Œæ•´å“åº”å¯¹è±¡
      const fullResponse = {
        id: completion.id,
        object: completion.object,
        created: completion.created,
        model: completion.model,
        choices: completion.choices,
        usage: completion.usage,
      };

      return this.createOutput(
        {
          response: responseText,
          fullResponse,
        },
        responseText,
        `æ¨¡å‹ ${model} è°ƒç”¨æˆåŠŸ`
      );
    } catch (error) {
      // å¤„ç† OpenAI API é”™è¯¯
      if (error instanceof OpenAI.APIError) {
        return this.createError(`API é”™è¯¯: ${error.status} - ${error.message}`);
      }

      // å¤„ç†ä¸­æ­¢é”™è¯¯
      if ((error as Error).name === "AbortError") {
        return this.createError("è¯·æ±‚å·²ä¸­æ­¢");
      }

      // å¤„ç†å…¶ä»–é”™è¯¯
      return this.createError(error as Error);
    }
  }
}
